{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9df7947c55971f4d",
   "metadata": {},
   "source": [
    "## Componentes Conectados\n",
    "Existem duas funções no OpenCV que podem ser usadas para localizar componentes conectados: cv2.connectedComponents e cv2.connectedComponentsWithStats. Ambos usam os mesmos argumentos: a imagem binária cujos componentes devem ser encontrados, o tipo de conectividade e a profundidade da imagem de saída\n",
    "\n",
    "cv2.connectedComponents é mais simples e retorna uma tupla de números de componentes e uma imagem com rótulos para componentes (labelmap). Além das saídas da função anterior, cv2.connectedComponentsWithStats também retorna estatísticas sobre cada componente e as localizações dos centróides dos componentes.\n",
    "\n",
    "### Função cv2.connectedComponentsWithStats\n",
    "img_output = cv2.connectedComponentsWithStats(src, connectivity, dtype)\n",
    "\n",
    "- src = Imagem Original Binarizada\n",
    "- connectivity = Conectividade dos Pixels (4 ou 8)\n",
    "- dtype = tipo de componentes\n",
    "    - CV_8U: 1-byte unsigned integer (unsigned char).\n",
    "    - CV_32S: 4-byte signed integer (int).\n",
    "    - CV_32F: 4-byte floating point (float)\n",
    "Essa função irá retornar o número de labels (objetos) detectados, suas respectivas Labels, os pontos onde se encontra o objeto (X, Y, H, W e Área) e por fim o centroide do objeto detectado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0587cd3110a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "from glob import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Endereco das imagens\n",
    "img_names = glob(os.path.join(os.getcwd(), 'images_06', '*.jpg'))\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc8cb1419d5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Imagens a serem analisadas: {img_names}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8c18ebb103f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ler todas as imagens na pasta e plotar\n",
    "for fn in img_names:\n",
    "\n",
    "    areas = list()\n",
    "\n",
    "    # Imagem de entrada\n",
    "    img = cv2.imread(fn, 1)\n",
    "\n",
    "    # Separar os canais da imagens\n",
    "    B, G, R = cv2.split(img)\n",
    "\n",
    "    # Filtro bilateral e Blur - Redução de ruídos e melhora de bordas\n",
    "    img_bil = cv2.bilateralFilter(G, 1, 90, 90)\n",
    "    img_blur = cv2.blur(img_bil, (5,5))\n",
    "\n",
    "    # Converter todos os píxels entre 1-195 para 0 e os outros para 1\n",
    "    img_th = cv2.threshold(img_blur, 190, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Dilatar as imagens\n",
    "    img_dilate = cv2.dilate(img_th, np.ones((4,4),np.uint8), iterations = 1)\n",
    "\n",
    "   # Aplicar connectedComponents para detectar pixels conectados\n",
    "    numLabels, labels, stats, centroids = cv2.connectedComponentsWithStats(img_dilate, 4, cv2.CV_8U)\n",
    "\n",
    "    areas.append(stats)\n",
    "    df_areas = pd.DataFrame(areas[0], columns=['X', 'Y', 'W', 'H', 'AREA'])\n",
    "    df_areas.drop(df_areas.index[0], inplace=True)\n",
    "    parafusos = df_areas[df_areas['AREA'] > 900]\n",
    "    porcas = df_areas[df_areas['AREA'] < 899]\n",
    "\n",
    "    # Mapeie rótulos de componentes para valor de matiz, 0-179 é o intervalo de matiz no OpenCV\n",
    "    label_hue = np.uint8(179*labels/np.max(labels))\n",
    "    blank_ch = 255*np.ones_like(label_hue)\n",
    "    labeled_img = cv2.merge([label_hue, blank_ch, blank_ch])\n",
    "\n",
    "    # Converte HSV->BGR\n",
    "    labeled_img = cv2.cvtColor(labeled_img, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # BG preto\n",
    "    labeled_img[label_hue == 0] = 0\n",
    "\n",
    "    qntd_elem = numLabels - 1\n",
    "\n",
    "    flag = True\n",
    "\n",
    "    if len(parafusos) != 10:\n",
    "        print(f'Falta {abs(len(parafusos) - 10)} parafusos')\n",
    "        cv2.putText(img, f'Falta {abs(len(parafusos) - 10)} parafusos',(50, 50), font, 1.5,(255,255,255),2,cv2.LINE_AA)\n",
    "        flag = False\n",
    "\n",
    "\n",
    "    if len(porcas) != 10:\n",
    "        print(f'Falta {abs(len(porcas) - 10)} porcas')\n",
    "        cv2.putText(img, f'Falta {abs(len(porcas) - 10)} porcas',(50, 750), font, 1.5,(255,255,255),2,cv2.LINE_AA)\n",
    "        flag = False\n",
    "\n",
    "    if flag:\n",
    "        print('Conjunto Aprovado')\n",
    "        cv2.putText(img, 'Conjunto Aprovado',(200, 750), font, 1.5,(255,255,255),2,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "    img_concate = cv2.hconcat([cv2.cvtColor(img, cv2.COLOR_BGR2RGB), cv2.cvtColor(labeled_img, cv2.COLOR_BGR2RGB)])\n",
    "    img_text = np.zeros((img_concate.shape[0], 50), dtype=np.uint8)\n",
    "    imagem_total = cv2.hconcat([cv2.cvtColor(img_concate, cv2.COLOR_BGR2RGB), cv2.cvtColor(img_text, cv2.COLOR_BGR2RGB)])\n",
    "    plt.imshow(imagem_total)\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Imagens\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
