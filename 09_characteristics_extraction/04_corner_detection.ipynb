{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração de Características - Detecção de cantos\n",
    "\n",
    "### Teoria\n",
    "### O que é uma feature?\n",
    "\n",
    "1. Na visão computacional, geralmente precisamos encontrar pontos de correspondência diferentes entre frames de um ambiente. Por quê? Se soubermos como duas imagens se relacionam, podemos usar as duas imagens para extrair informações delas.\n",
    "2. Quando dizemos pontos correspondentes, estamos nos referindo, em um sentido geral, a características na cena que podemos reconhecer facilmente. Então, quais características devem ser procuradas?\n",
    "Aquelas que devem ser exclusivamente reconhecível \n",
    "\n",
    "\n",
    "### Tipos de features em uma imagem\n",
    "\n",
    "Para mencionar alguns:\n",
    "\n",
    "    1. Arestas\n",
    "    2. Cantos (também conhecidos como pontos de interesse)\n",
    "    3. Blobs (também conhecidos como regiões de interesse) \n",
    "\n",
    "Nesta aula, vamos estudar os recursos de canto, especificamente.\n",
    "\n",
    "### Por que um canto é tão especial?\n",
    "\n",
    "Porque, como é a intersecção de duas arestas, representa um ponto no qual as direções dessas duas arestas mudam. Assim, o gradiente da imagem (em ambas as direções) tem uma alta variação, que pode ser usada para detectá-lo.\n",
    "\n",
    "### Como funciona?\n",
    "\n",
    "* Vamos procurar cantos. Como os cantos representam uma variação no gradiente da imagem, procuramos por essa \"variação\".\n",
    "* Considere uma imagem em escala de cinza $I$. Vamos varrer uma janela $(w(x, y))$ (com deslocamentos $(u)$ na direção xe $(v)$ na direção y) $(I)$ e calcularemos a variação de intensidade.\n",
    "\n",
    "### $E(u, v) = \\sum_{x, y}w(x, y) [I(x + u, y + v) - I (x, y)]^{2}]$\n",
    "\n",
    "Onde:\n",
    "\n",
    "* $w(x, y)$ é a janela na posição $(x, y)$\n",
    "* $(I(x, y)$ é a intensidade em $(x, y)$\n",
    "* $I(x + u, y + v)$ é a intensidade na janela movida $(x + u, y + v)$ \n",
    "\n",
    "Como estamos à procura de janelas com cantos, estamos à procura de janelas com uma grande variação de intensidade. Por isso, temos que maximizar a equação acima, especificamente o termo:\n",
    "\n",
    "### $\\sum_{x, y}I(x + u, y + v) -I (x, y)]^{2}$\n",
    "\n",
    "* Usando a expansão de Taylor:\n",
    "\n",
    "### $E(u, v)=\\sum_{x, y}I(x, y) + uI_{x} + vI_{y} - I(x, y)]^{2}$\n",
    "\n",
    "Expandindo a equação e cancelando corretamente:\n",
    "\n",
    "### $E (u, v)=\\sum _{x, y}u^{2}I_{x}^{2} + 2uvI_{x} I_{y} + v^{2}I_{y}^{2}$\n",
    "\n",
    "\n",
    "Uma pontuação é calculada para cada janela, para determinar se ela pode conter um canto:\n",
    "\n",
    "### $R = det(M) - k(trace(M))^{2}$\n",
    "\n",
    "Onde:\n",
    "* $det (M) = \\lambda_{1} \\lambda_{2})$\n",
    "* $trace (M) = \\lambda_{1} + \\lambda_{2}$\n",
    "\n",
    "Uma janela com uma pontuação $R$ maior que um determinado valor é considerada um \"canto\"\n",
    "\n",
    "Importando as bibliotecas e lendo a imagem em tons de cinza\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"images/04.jpg\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNÇÃO **cv.cornerHarris(img, blockSize, ksize, k)**\n",
    "\n",
    "Entrada: \n",
    "1. img = Imagem de entrada em tons de cinza\n",
    "2. blockSize = Tamanho dos píxels vizinhos considerados como cantos para detecção.\n",
    "3. ksize = Parâmetro de abertura do derivado de Sobel usado.\n",
    "4. k = Parâmetro livre do detector Harris.\n",
    "\n",
    "Saída:\n",
    "1. Pontos de detecção de canto da imagem."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "gray = np.float32(gray)\n",
    "\n",
    "dst = cv2.cornerHarris(gray, 2, 3, 0.01)\n",
    "element_estr = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
    "dst = cv2.dilate(dst, element_estr)\n",
    "\n",
    "img[dst > 0.05*dst.max()] = [0,0,255]\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
